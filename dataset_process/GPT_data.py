import json
from pathlib import Path
from torch.utils.data import Dataset
from typing import Union
import random

default_data_raw_dir = Path(__file__).parent/"data_raw"

dataset_info = {
        "name": "GPT4o_data", 
        "des": """Data generated by GPT4o based on the input.""",
        "dataset_type": ""
    }

class GPT4o(Dataset):
    def __init__(self, sample=[], *args, **kwargs):
        self.data = [sample]
        print(f"Loaded dataset with {len(self)} elements")

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return self.data[idx]
    
    def samples(self, n=5):
        return [get_processed_kvs(self.data[idx]) for idx in random.sample(range(len(self)), n)]
    
support_template_keys = []

def get_processed_kvs(sample, keys=support_template_keys):
    # global support_template_keys
    kvs = dict(sample)
    kvs["dataset_name"] = dataset_info["name"]
    kvs["dataset_type"] = dataset_info.get("dataset_type", "")
    # kvs["prompts"] = [sample["prompt"]]
    return kvs

def get_default_dataset():
    return GPT4o()

if __name__ == "__main__":
    known_set = get_default_dataset()
    kvs = get_processed_kvs(known_set[0], keys=support_template_keys)
    print(kvs)