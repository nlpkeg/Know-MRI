{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7308f250-674d-4414-8cf3-22eb1934bcd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:transformers_modules.Qwen-1_8B.modeling_qwen:The model is automatically converting to bf16 for faster inference. If you want to disable the automatic precision, please manually add bf16/fp16/fp32=True to \"AutoModelForCausalLM.from_pretrained\".\n",
      "WARNING:transformers_modules.Qwen-1_8B.modeling_qwen:Try importing flash-attention for faster inference...\n",
      "WARNING:transformers_modules.Qwen-1_8B.modeling_qwen:Warning: import flash_attn rotary fail, please install FlashAttention rotary to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/rotary\n",
      "WARNING:transformers_modules.Qwen-1_8B.modeling_qwen:Warning: import flash_attn rms_norm fail, please install FlashAttention layer_norm to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/layer_norm\n",
      "WARNING:transformers_modules.Qwen-1_8B.modeling_qwen:Warning: import flash_attn fail, please install FlashAttention to get higher efficiency https://github.com/Dao-AILab/flash-attention\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module 'kv_template' has no attribute 'dataset_info'\n",
      "Loaded dataset with 1209 elements\n",
      "loading model: /root/autodl-tmp/Qwen-1_8B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:accelerate.utils.modeling:We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004926443099975586,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Loading checkpoint shards",
       "rate": null,
       "total": 2,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "090da67387ce4d71adf1d7cade579ce2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/autodl-tmp/Qwen-1_8B model loaded\n",
      "{'output': '', 'image': [], 'table': [{'table_name': 'Hidden states top token', 'table_list': [{'Layer name': 'Layer_0', 'Top tokens': \"['ÔøΩÔøΩ', ' useRouter', 'wick']\"}, {'Layer name': 'Layer_1', 'Top tokens': \"['‚Ñâ', 'r√§n', 'h√§lt']\"}, {'Layer name': 'Layer_2', 'Top tokens': \"['Âò¨', 'Âó´', 'ÂÜ∞Ê∑á']\"}, {'Layer name': 'Layer_3', 'Top tokens': \"['Âò¨', 'Âó´', 'ÁòÜ']\"}, {'Layer name': 'Layer_4', 'Top tokens': \"['Âò¨', 'Âó´', ' DisplayName']\"}, {'Layer name': 'Layer_5', 'Top tokens': \"['Âò¨', 'Âó´', ' DisplayName']\"}, {'Layer name': 'Layer_6', 'Top tokens': \"['Âò¨', ' NavLink', ' PureComponent']\"}, {'Layer name': 'Layer_7', 'Top tokens': \"['h√§lt', ' behalf', 'Âò¨']\"}, {'Layer name': 'Layer_8', 'Top tokens': \"['Ë∏Ö', 'Âò¨', ' behalf']\"}, {'Layer name': 'Layer_9', 'Top tokens': \"['h√§lt', 'Âò¨', 'Áç≠']\"}, {'Layer name': 'Layer_10', 'Top tokens': \"['Âò¨', 'üâë', 'Áãû']\"}, {'Layer name': 'Layer_11', 'Top tokens': \"['Âò¨', 'üâë', 'ÁòÜ']\"}, {'Layer name': 'Layer_12', 'Top tokens': \"[' handleClick', 'ÁòÜ', 'Âò¨']\"}, {'Layer name': 'Layer_13', 'Top tokens': \"['ÁòÜ', 'Âò¨', ' handleClick']\"}, {'Layer name': 'Layer_14', 'Top tokens': \"['ÁòÜ', 'Âò¨', ' handleClick']\"}, {'Layer name': 'Layer_15', 'Top tokens': \"['ÁòÜ', 'Ëàõ', 'Ë∂î']\"}, {'Layer name': 'Layer_16', 'Top tokens': \"['ÁòÜ', 'uzu', ' ()=>']\"}, {'Layer name': 'Layer_17', 'Top tokens': \"['ÁòÜ', 'Â≠£Âêé', ' behalf']\"}, {'Layer name': 'Layer_18', 'Top tokens': \"['Â≠£Âêé', 'ÂïÅ', ' behalf']\"}, {'Layer name': 'Layer_19', 'Top tokens': \"[' behalf', 'Â≠£Âêé', ' CBS']\"}, {'Layer name': 'Layer_20', 'Top tokens': \"[' CBS', 'Â≠£Âêé', 'Âí£']\"}, {'Layer name': 'Layer_21', 'Top tokens': \"[' CBS', 'Â≠£Âêé', ' Comedy']\"}, {'Layer name': 'Layer_22', 'Top tokens': \"['Â≠£Âêé', 'ÂïÅ', ' Network']\"}, {'Layer name': 'Layer_23', 'Top tokens': \"[' CBS', ' the', ' ']\"}, {'Layer name': 'Layer_24', 'Top tokens': \"[' CBS', ' Thursday', ' September']\"}], 'table_des': 'We use the lm head to decode the semantic information in the hidden states layer across the layer.', 'table_res': 'In the forward propagation of the model: \\nThe final token predicted by the model is  CBS.'}], 'result_des': '', 'origin_data': {'top_tokens': [['ÔøΩÔøΩ', ' useRouter', 'wick'], ['‚Ñâ', 'r√§n', 'h√§lt'], ['Âò¨', 'Âó´', 'ÂÜ∞Ê∑á'], ['Âò¨', 'Âó´', 'ÁòÜ'], ['Âò¨', 'Âó´', ' DisplayName'], ['Âò¨', 'Âó´', ' DisplayName'], ['Âò¨', ' NavLink', ' PureComponent'], ['h√§lt', ' behalf', 'Âò¨'], ['Ë∏Ö', 'Âò¨', ' behalf'], ['h√§lt', 'Âò¨', 'Áç≠'], ['Âò¨', 'üâë', 'Áãû'], ['Âò¨', 'üâë', 'ÁòÜ'], [' handleClick', 'ÁòÜ', 'Âò¨'], ['ÁòÜ', 'Âò¨', ' handleClick'], ['ÁòÜ', 'Âò¨', ' handleClick'], ['ÁòÜ', 'Ëàõ', 'Ë∂î'], ['ÁòÜ', 'uzu', ' ()=>'], ['ÁòÜ', 'Â≠£Âêé', ' behalf'], ['Â≠£Âêé', 'ÂïÅ', ' behalf'], [' behalf', 'Â≠£Âêé', ' CBS'], [' CBS', 'Â≠£Âêé', 'Âí£'], [' CBS', 'Â≠£Âêé', ' Comedy'], ['Â≠£Âêé', 'ÂïÅ', ' Network'], [' CBS', ' the', ' '], [' CBS', ' Thursday', ' September']]}}\n"
     ]
    }
   ],
   "source": [
    "from diagnose import diagnose\n",
    "from dataset_process import knowns, ZsRE, counterfact\n",
    "from models import llama, gptj, gpt2, qwen, bert, t5, chatglm2, internlm, baichuan\n",
    "from methods import logit_lens\n",
    "\n",
    "dataset = knowns.KnownsDataset(loc=knowns.default_loc)\n",
    "sample = knowns.get_processed_kvs(dataset[3], logit_lens.requires_input_keys)\n",
    "# dataset = ZsRE.ZsREDataset(loc=ZsRE.default_loc)\n",
    "# sample = ZsRE.get_processed_kvs(dataset[0], kn.requires_input_keys)\n",
    "# dataset = counterfact.CounterfactDataset(loc=counterfact.default_loc)\n",
    "# sample = counterfact.get_processed_kvs(dataset[0], logit_lens.requires_input_keys)\n",
    "result = diagnose.diagnosing(sample=sample, model_name_or_path=qwen, method=logit_lens.name)\n",
    "\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
