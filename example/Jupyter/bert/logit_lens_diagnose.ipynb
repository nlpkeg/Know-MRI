{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7308f250-674d-4414-8cf3-22eb1934bcd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "If you want to use `BertLMHeadModel` as a standalone, add `is_decoder=True.`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module 'kv_template' has no attribute 'dataset_info'\n",
      "Loaded dataset with 1209 elements\n",
      "loading model: /root/autodl-fs/bert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /root/autodl-fs/bert were not used when initializing BertLMHeadModel: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertLMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertLMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Using eos_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/autodl-fs/bert model loaded\n",
      "{'output': '', 'image': [], 'table': [{'table_name': 'Hidden states top token', 'table_list': [{'Layer name': 'Layer_0', 'Top tokens': \"['[ S E P ]', '[ C L S ]', '[ M A S K ]']\"}, {'Layer name': 'Layer_1', 'Top tokens': \"['[ C L S ]', '[ S E P ]', '.']\"}, {'Layer name': 'Layer_2', 'Top tokens': \"['[ C L S ]', '[ S E P ]', '[ M A S K ]']\"}, {'Layer name': 'Layer_3', 'Top tokens': \"['[ C L S ]', '[ S E P ]', '# # r o v e']\"}, {'Layer name': 'Layer_4', 'Top tokens': \"['[ S E P ]', '[ C L S ]', '# # r o v e']\"}, {'Layer name': 'Layer_5', 'Top tokens': \"['[ S E P ]', '[ C L S ]', '# # r o v e']\"}, {'Layer name': 'Layer_6', 'Top tokens': \"['[ S E P ]', '[ C L S ]', '# # r o v e']\"}, {'Layer name': 'Layer_7', 'Top tokens': \"['[ S E P ]', '# # r o v e', '# # l a k e']\"}, {'Layer name': 'Layer_8', 'Top tokens': \"['[ S E P ]', '# # l a k e', 'p r e f e c t']\"}, {'Layer name': 'Layer_9', 'Top tokens': \"['# # l a k e', 'p r e f e c t', '# # r o v e']\"}, {'Layer name': 'Layer_10', 'Top tokens': \"['# # u n o', '# # i n e d', '# # r o v e']\"}, {'Layer name': 'Layer_11', 'Top tokens': \"['q u a k e r s', '# # e v i l l e', '# # i c o']\"}, {'Layer name': 'Layer_12', 'Top tokens': \"['# # v e y', '# # a n n', '# # f o r d']\"}], 'table_des': 'We use the lm head to decode the semantic information in the hidden states layer across the layer.', 'table_res': 'In the forward propagation of the model: \\nThe final token predicted by the model is # # v e y.'}], 'result_des': '', 'origin_data': {'top_tokens': [['[ S E P ]', '[ C L S ]', '[ M A S K ]'], ['[ C L S ]', '[ S E P ]', '.'], ['[ C L S ]', '[ S E P ]', '[ M A S K ]'], ['[ C L S ]', '[ S E P ]', '# # r o v e'], ['[ S E P ]', '[ C L S ]', '# # r o v e'], ['[ S E P ]', '[ C L S ]', '# # r o v e'], ['[ S E P ]', '[ C L S ]', '# # r o v e'], ['[ S E P ]', '# # r o v e', '# # l a k e'], ['[ S E P ]', '# # l a k e', 'p r e f e c t'], ['# # l a k e', 'p r e f e c t', '# # r o v e'], ['# # u n o', '# # i n e d', '# # r o v e'], ['q u a k e r s', '# # e v i l l e', '# # i c o'], ['# # v e y', '# # a n n', '# # f o r d']]}}\n"
     ]
    }
   ],
   "source": [
    "from diagnose import diagnose\n",
    "from dataset_process import knowns, ZsRE, counterfact\n",
    "from models import llama, gptj, gpt2, qwen, bert, t5, chatglm2, internlm, baichuan\n",
    "from methods import logit_lens\n",
    "\n",
    "dataset = knowns.KnownsDataset(loc=knowns.default_loc)\n",
    "sample = knowns.get_processed_kvs(dataset[3], logit_lens.requires_input_keys)\n",
    "# dataset = ZsRE.ZsREDataset(loc=ZsRE.default_loc)\n",
    "# sample = ZsRE.get_processed_kvs(dataset[0], kn.requires_input_keys)\n",
    "# dataset = counterfact.CounterfactDataset(loc=counterfact.default_loc)\n",
    "# sample = counterfact.get_processed_kvs(dataset[0], logit_lens.requires_input_keys)\n",
    "result = diagnose.diagnosing(sample=sample, model_name_or_path=bert, method=logit_lens.name)\n",
    "\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
